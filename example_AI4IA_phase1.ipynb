{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI4IA Hackathon Phase 1: présentation du DataSet et exemple.s de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:\n",
    "\n",
    "Ce Notebook est mis à disposition des candidats du Challenge AI4IA-1ere Edition et est exclusivement dédié à cet évènement.\n",
    "\n",
    "Le but de cet exemple classique est d'aider à la compréhension de ce qui est attendu des candidats, d'introduire les outils mis à disposition ainsi que les jeux de données et leur format. \n",
    "\n",
    "Les éléments fournis sont les suivants:\n",
    "- jeu de données d'exemple (./data/DataSet_ex) sous la forme de plusieurs fichiers .csv, chacun correspondant à un signal d'excitation ;\n",
    "- fichiers de définition des modèles et de leurs interfaces (cf. model_api.py et les exemples my_model1.py / my_model2.py). Note: le fichier de définition des modèles est la principale soumission des candidats: c'est à ce niveau qu'il est demandé d'implémenter l'architecture du modèle, ainsi que les stratégies d'inférence et d'entrainement;\n",
    "- script générique pour le lancement d'un entraînement sur une instance AWS via sagemaker ou en local (sagemajer_api.py);\n",
    "- scripts génériques pour l'évaluation des performances du modèle sur une instance AWS via sagemaker ou en local telles que définies pas les évaluateurs (les mêmes critères d'évaluation/métriques seront appliquées durant la phase d'évalutation, en considérant un jeu de données identique pour chaque candidat ainsi qu'une machine/instance AWS identique);\n",
    "- une classe de test unitaire (cf. test_submission.py) permettant à tout instant de tester si la solution développée (la définition du modèle notamment) est conforme à ce qui est attendu et à ce qui sera mis en oeuvre lors de la phase d'évaluation. \n",
    "\n",
    "Note: il est donc indispensable que le modèle soumis par l'équipe candidate valide tous les tests unitaires et présente les caractéristiques nécessaires à l'évaluation de ses performances sur des instances AWS avec un fichier de test csv arbitraire (via calc_metrics_on_sagemaker.py). Il est donc vivement recommandé de s'assurer que le modèle développé présente bien ces caractéristiques.\n",
    "\n",
    "Author: François Caire \\\n",
    "Maintainer: François Caire \\\n",
    "Email: francois.caire at skf.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    "1. [Chargement des Modules](#1-bullet)\n",
    "2. [Chargement et exploration du DataSet](#2-bullet)\n",
    "3. [Exemple Rudimentaire d'apprentissage](#3-bullet)\n",
    "4. [Entraînement sur AWS SageMaker](#4-bullet)\n",
    "5. [Evaluation de la solution en local et AWS SageMaker](#5-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des Modules <a class=\"anchor\" id=\"1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on importe les modules classiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8604/2487817686.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'autoreload'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'2'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmpl\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgridspec\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mgridspec\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal as sg\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import interpn,interp1d,RegularGridInterpolator, Akima1DInterpolator\n",
    "\n",
    "import time\n",
    "from tqdm import notebook\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import tarfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute des paramètres d'affichage et de tracé..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "mpl.rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.linspace(0,1,251)\n",
    "y=np.sin(t*10*2*np.pi)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(t,y,label='sinusoid')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chargement et Exploration/Tracé du DataSet d'exemple <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_data = \"./data/DataSet_ex/\"\n",
    "names = [\"input\"+str(k) for k in range(1,6)]\n",
    "\n",
    "d = {}\n",
    "for name in names:\n",
    "    d[name] = pd.read_csv(rep_data + name + '.csv',sep=',',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['input1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_input   = 1\n",
    "N_outputs = 5\n",
    "N_signals = len(names)\n",
    "\n",
    "for name in names:\n",
    "    fig,ax = plt.subplots(N_outputs,1,figsize=(15,15))\n",
    "    for k in range(N_outputs):\n",
    "        d[name].plot(ax=ax[k],x='Time',y=[1,k+2],grid='on')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.utilities.utility_functions import *\n",
    "\n",
    "t,x,y = load_data_csv(\"data/DataSet_ex/input1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exemple rudimentaire d'apprentissage <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Chargement des modules d'intérêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload,import_module\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On charge ici le modele créé specifiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition = \"my_model2\"\n",
    "\n",
    "MyModel = import_module('sources.utilities.' + model_definition).MyModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier grâce aux tests unitaire que le modele est valide pour soumission (NB: il doit calculer cinq sorties pour les cinq grandeurs d'intérêt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sources/utilities/test_submission.py my_model1\n",
    "!python3 sources/utilities/test_submission.py my_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize \"./sources/utilities/my_model2.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. On selectionne le/les signaux utiles pour l'apprentissage et ceux pour la validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_data   = \"data/DataSet_ex/\"\n",
    "file_train = \"input4.csv\"\n",
    "\n",
    "t_train,x_train,y_train = load_data_csv(rep_data+file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    Ndecim=5\n",
    "    outputs_indexes = [0]\n",
    "    model = MyModel.create_model(torch.cuda.is_available(), epochs=150, lr=0.05, output_size = len(outputs_indexes))\n",
    "\n",
    "    model.fit(xs=x_train[::Ndecim], ys=[y_train[k][::Ndecim] for k in outputs_indexes])\n",
    "    \n",
    "    retrain = False\n",
    "\n",
    "y_pred_train = model.predict_timeseries(x_train[::Ndecim])\n",
    "for k in range(len(outputs_indexes)):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(9,6))\n",
    "    ax.plot(t_train[::Ndecim],y_train[outputs_indexes[k]][::Ndecim],'b',t_train[::Ndecim],y_pred_train[k],'--r') \n",
    "    plt.grid()\n",
    "    plt.legend([\"ref.\",\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test  = \"input1.csv\"\n",
    "t_test,x_test,y_test = load_data_csv(rep_data+file_test)\n",
    "\n",
    "y_pred = model.predict_timeseries(x_test[::Ndecim])\n",
    "\n",
    "for k in range(len(outputs_indexes)):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(9,6))\n",
    "    ax.plot(t_test[::Ndecim],y_test[outputs_indexes[k]][::Ndecim],'b',t_test[::Ndecim],y_pred[k],'--r') \n",
    "    plt.grid()\n",
    "    plt.legend([\"ref.\",\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Lancement sur AWS SageMaker <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Test local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet de vérifier que tout est ok avant de monter l'image sur une instance amazon (ce qui peut être long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = \"data/DataSet_ex/\"\n",
    "file_train = \"input4.csv\"\n",
    "data = rep + file_train\n",
    "\n",
    "use_gpu = True\n",
    "epochs = 40\n",
    "model_dir = \"./models\"\n",
    "model_name = \"model0\"\n",
    "lr = 0.05\n",
    "Ndecim = 5\n",
    "outputs_indexes = [0]\n",
    "outputs_ind = ','.join([str(k+1) for k in outputs_indexes])\n",
    "hyper_fileName = \"hyper.json\"\n",
    "\n",
    "%run sources/sagemaker_api.py --use_gpu $use_gpu --lr $lr --epochs $epochs \\\n",
    "                              --data_dir $rep --train_fileName $file_train --model_dir $model_dir \\\n",
    "                              --outputs_indexes $outputs_ind --Ndecim $Ndecim --hyper_fileName $hyper_fileName\\\n",
    "                              --model_def_file $model_definition \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train,x_train,y_train = load_data_csv(rep+file_train,Ndecim=Ndecim)\n",
    "file_test  = \"input3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_timeseries(x_train)\n",
    "\n",
    "No = len(outputs_indexes)\n",
    "fig,ax = plt.subplots(No,1,figsize=(9,3*No))\n",
    "if No>1:\n",
    "    for k in range(No):\n",
    "        ax[k].plot(t_train,y_train[outputs_indexes[k]],'b',t_train,y_pred[k],'--r')\n",
    "        ax[k].grid()\n",
    "        ax[k].legend(['ref,pred'])\n",
    "else:\n",
    "    ax.plot(t_train,y_train[outputs_indexes[0]],'b',t_train,y_pred[0],'--r')\n",
    "    ax.grid()\n",
    "    ax.legend(['ref,pred'])\n",
    "    \n",
    "t_test,x_test,y_test = load_data_csv(rep+file_test,Ndecim=Ndecim)\n",
    "y_pred = model.predict_timeseries(x_test)\n",
    "\n",
    "fig,ax = plt.subplots(No,1,figsize=(9,3*No))\n",
    "if No>1:\n",
    "    for k in range(No):\n",
    "        ax[k].plot(t_test,y_test[outputs_indexes[k]],'b',t_test,y_pred[k],'--r')\n",
    "        ax[k].grid()\n",
    "        ax[k].legend(['ref,pred'])\n",
    "else:\n",
    "    ax.plot(t_test,y_test[outputs_indexes[0]],'b',t_test,y_test[0],'--r')\n",
    "    ax.grid()\n",
    "    ax.legend(['ref,pred'])  \n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Depôt des données sur S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix_in  = 'DEMO-AI4IA/input'\n",
    "prefix_out = 'DEMO-AI4IA/model'\n",
    "role = \"arn:aws:iam::<...>:role/service-role/AmazonSageMaker-ExecutionRole-<...>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_data = './data/DataSet_ex/'\n",
    "\n",
    "input_channel = sagemaker_session.upload_data(path=rep_data, bucket=bucket, key_prefix=prefix_in)\n",
    "print('input file (in this case, just an S3 path): {}'.format(input_channel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creation des instances et paramétrage de l'estimateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f's3://'+bucket+'/'+prefix_out\n",
    "\n",
    "outputs_indexes = [0,1,2]\n",
    "outputs_ind = ','.join([str(k+1) for k in outputs_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_GRU'\n",
    "max_run = 60*60*6 # Max time in seconds\n",
    "\n",
    "sagemaker_estimator,framework_version = model.get_sagemaker_estimator_class()\n",
    "estimator = sagemaker_estimator(entry_point = 'sagemaker_api.py',\n",
    "                                source_dir  = 'sources',\n",
    "                                role = role,\n",
    "                                py_version = 'py3',\n",
    "                                max_run=max_run,\n",
    "                                framework_version = framework_version,\n",
    "                                instance_count = 1,\n",
    "                                instance_type='ml.p3.2xlarge', #'ml.m4.xlarge',#'ml.p2.xlarge',#'ml.p3.2xlarge',#\n",
    "                                output_path=f's3://'+bucket+'/'+prefix_out,\n",
    "                                hyperparameters={\n",
    "                                                    'use_gpu':True,\n",
    "                                                    'epochs':350000,\n",
    "                                                    'lr':.05,\n",
    "                                                    'outputs_indexes': outputs_ind,\n",
    "                                                    'Ndecim':5,\n",
    "                                                    'train_fileName':file_train,\n",
    "                                                    'model_def_file':'my_model2'\n",
    "                                }\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'training': input_channel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "trained_model_location = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "display('Model is here: {}'.format(trained_model_location))\n",
    "\n",
    "s3 = boto3.resource('s3')    \n",
    "s3.Bucket(bucket).download_file(os.path.join(prefix_out,desc['TrainingJobName'],'output/model.tar.gz'),'./models/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/model0'\n",
    "\n",
    "with tarfile.open('./models/model.tar.gz','r:gz') as archived:\n",
    "    archived.extractall(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_timeseries(x_train)\n",
    "\n",
    "No = len(outputs_indexes)\n",
    "fig,ax = plt.subplots(No,1,figsize=(9,3*No))\n",
    "if No>1:\n",
    "    for k in range(No):\n",
    "        ax[k].plot(t_train,y_train[outputs_indexes[k]],'b',t_train,y_pred[k],'--r')\n",
    "        ax[k].grid()\n",
    "        ax[k].legend(['ref,pred'])\n",
    "else:\n",
    "    ax.plot(t_train,y_train[outputs_indexes[0]],'b',t_train,y_pred[0],'--r')\n",
    "    ax.grid()\n",
    "    ax.legend(['ref,pred'])\n",
    "\n",
    "t_test,x_test,y_test = load_data_csv(rep+file_test,Ndecim=Ndecim)\n",
    "y_pred = model.predict_timeseries(x_test)\n",
    "fig,ax = plt.subplots(No,1,figsize=(9,3*No))\n",
    "if No>1:\n",
    "\n",
    "    for k in range(No):\n",
    "        ax[k].plot(t_test,y_test[outputs_indexes[k]],'b',t_test,y_pred[k],'--r')\n",
    "        ax[k].grid()\n",
    "        ax[k].legend(['ref,pred'])\n",
    "else:\n",
    "    ax.plot(t_test,y_test[outputs_indexes[0]],'b',t_test,y_test[0],'--r')\n",
    "    ax.grid()\n",
    "    ax.legend(['ref,pred'])  \n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = \"data/DataSet_ex/\"\n",
    "file_train = \"input1.csv\"\n",
    "data = rep + file_train\n",
    "\n",
    "use_gpu = True\n",
    "epochs = 40\n",
    "model_dir = \"./models/model1\"\n",
    "model_name = \"model0\"\n",
    "lr = 0.05\n",
    "Ndecim = 5\n",
    "outputs_indexes = [0,1,2,3,4]\n",
    "outputs_ind = ','.join([str(k+1) for k in outputs_indexes])\n",
    "hyper_fileName = \"hyper.json\"\n",
    "\n",
    "%run sources/sagemaker_api.py --use_gpu $use_gpu --lr $lr --epochs $epochs \\\n",
    "                              --data_dir $rep --train_fileName $file_train --model_dir $model_dir \\\n",
    "                              --outputs_indexes $outputs_ind --Ndecim $Ndecim --hyper_fileName $hyper_fileName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation des solutions <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Recuperation des paramètres (modele et entraînement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/model1/hyper.json\",\"r\") as f:\n",
    "    dHyper = json.load(f)\n",
    "\n",
    "with open(\"models/model1/model_kwargs.json\",\"r\") as f:\n",
    "    dKwargs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dHyper,dKwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Local metric tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MyModel(**dKwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/DataSet_ex\"\n",
    "hyper_filename  = \"hyper.json\"\n",
    "kwargs_filename = \"model_kwargs.json\"\n",
    "test_filename   = 'input2.csv'\n",
    "model_dir       = './models/model1'\n",
    "model_def_file  = 'my_model2'\n",
    "\n",
    "%run sources/calc_metrics.py --data_dir $data_dir \\\n",
    "                             --model_dir $model_dir \\\n",
    "                             --estimator_hyperParams_fileName $hyper_fileName \\\n",
    "                             --model_kwargs_fileName $kwargs_filename \\\n",
    "                             --test_fileName $test_filename \\\n",
    "                             --model_def_file $model_def_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./metrics/s2m_GRU2_metrics','r') as f: print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AWS Metrics tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dir = './metrics_sage'\n",
    "model_def_file = \"my_model1\"\n",
    "type_instance = 'ml.m5.xlarge' # Mention that the time limit is t on this specific type of instance\n",
    "\n",
    "%run calc_metrics_on_sagemaker.py --data_dir $data_dir \\\n",
    "                                  --model_dir $model_dir \\\n",
    "                                  --role $role \\\n",
    "                                  --estimator_hyperParams_fileName $hyper_fileName \\\n",
    "                                  --model_kwargs_fileName $kwargs_filename \\\n",
    "                                  --test_fileName $test_filename \\\n",
    "                                  --out_dir $metrics_dir \\\n",
    "                                  --model_def_file $model_def_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(metrics_dir,'s2m' '_' + 'GRU1' + '_metrics'),'r') as f:  print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dir = './metrics_sage'\n",
    "model_def_file = \"my_model2\"\n",
    "\n",
    "%run calc_metrics_on_sagemaker.py --data_dir $data_dir \\\n",
    "                                  --model_dir $model_dir \\\n",
    "                                  --role $role \\\n",
    "                                  --estimator_hyperParams_fileName $hyper_fileName \\\n",
    "                                  --model_kwargs_fileName $kwargs_filename \\\n",
    "                                  --test_fileName $test_filename \\\n",
    "                                  --out_dir $metrics_dir \\\n",
    "                                  --model_def_file $model_def_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(metrics_dir,'s2m' '_' + 'GRU2' + '_metrics'),'r') as f:  print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipreqs ./ --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}